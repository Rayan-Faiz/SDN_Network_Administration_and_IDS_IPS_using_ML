import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load and combine datasets
df1 = pd.read_csv('Normal_data.csv')
df2 = pd.read_csv('OVS.csv')
df_combined = pd.concat([df1, df2], ignore_index=True)

# Step 2: Preprocess the data
# Turn label into binary & drops string features
df_combined = df_combined.drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Timestamp'])
df_combined['Label'] = df_combined['Label'].apply(lambda x: 0 if x == 'Normal' else 1)
df_combined = df_combined.dropna()

X = df_combined.drop(columns=['Label'])
y = df_combined['Label']

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 5: Convert data to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train.values, dtype=torch.long)
y_test = torch.tensor(y_test.values, dtype=torch.long)

# Step 6: Create a simple SVM model using PyTorch
class SVM(nn.Module):
    def __init__(self, input_dim):
        super(SVM, self).__init__()
        self.fc = nn.Linear(input_dim, 2)  # 2 for binary classification
        
    def forward(self, x):
        return self.fc(x)

# Initialize the model, loss function, and optimizer
model = SVM(input_dim=X_train.shape[1])
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Step 7: Train the model with DataLoader
def train(model, criterion, optimizer, X_train, y_train, epochs=20, batch_size=64):
    model.train()
    dataset = TensorDataset(X_train, y_train)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    for epoch in range(epochs):
        epoch_loss = 0
        for batch_X, batch_y in dataloader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader)}')

train(model, criterion, optimizer, X_train, y_train)

# Step 8: Evaluate the model
model.eval()
with torch.no_grad():
    y_pred_train = torch.argmax(model(X_train), dim=1)
    y_pred_test = torch.argmax(model(X_test), dim=1)
    y_pred_proba = torch.softmax(model(X_test), dim=1)[:, 1].numpy()

# Calculate accuracy
train_accuracy = metrics.accuracy_score(y_train, y_pred_train)
test_accuracy = metrics.accuracy_score(y_test, y_pred_test)

print(f'Train Accuracy: {train_accuracy}')
print(f'Test Accuracy: {test_accuracy}')

# Step 9: Additional metrics

# Confusion Matrix
print('Confusion Matrix:')
conf_matrix = metrics.confusion_matrix(y_test, y_pred_test)
print(conf_matrix)

# Confusion Matrix Visualization
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')
plt.show()

# Classification Report
print('Classification Report:')
print(metrics.classification_report(y_test, y_pred_test))

# ROC Curve and AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba)
roc_auc = metrics.auc(fpr, tpr)

plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Precision-Recall Curve and AUC
precision, recall, _ = metrics.precision_recall_curve(y_test, y_pred_proba)
pr_auc = metrics.auc(recall, precision)

plt.figure(figsize=(6, 4))
plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR Curve (AUC = {pr_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='lower left')
plt.show()

# F1 Score
f1_score = metrics.f1_score(y_test, y_pred_test)
print(f'F1 Score: {f1_score}')

# Log Loss
log_loss = metrics.log_loss(y_test, y_pred_proba)
print(f'Log Loss: {log_loss}')

# Step 10: Save the model and the scaler
torch.save(model.state_dict(), 'svm_model.pth')
joblib.dump(scaler, 'scaler.pkl')

# Step 11: Load and use the model
loaded_model = SVM(input_dim=X_train.shape[1])
loaded_model.load_state_dict(torch.load('svm_model.pth'))
loaded_model.eval()
